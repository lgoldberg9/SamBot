{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading musings...\n",
      "Making bigrams...\n",
      "Making trigrams...\n",
      "Modding n-grams...\n",
      "Destroying stop words...\n",
      "Forming bigrams...\n",
      "Building spacy NLP parser...\n",
      "Lemmatizing bigrams...\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n",
      "Null bigram found\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "stop_words = stopwords.words('english')\n",
    "# stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "musings_path = 'sam_musings/'\n",
    "musings = os.listdir(musings_path)\n",
    "\n",
    "# Import Dataset\n",
    "print('Loading musings...')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "musings = '\\n'.join([open(musings_path + musing).read() for musing in musings])\n",
    "musing_sentences = tokenizer.tokenize(musings)\n",
    "df = pd.DataFrame([{'content': sentence} for sentence in musing_sentences])\n",
    "\n",
    "# Convert to list\n",
    "data = df.content.values.tolist()\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "        # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "print('Making bigrams...')\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "\n",
    "print('Making trigrams...')\n",
    "#trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "print('Modding n-grams...')\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "#trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        try:\n",
    "            doc = nlp(\" \".join(sent)) \n",
    "            texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "        except TypeError:\n",
    "            if len(sent) == 0:\n",
    "                print 'Null bigram found'\n",
    "            else:\n",
    "                print 'something is wrong with bigram: {}'.format(sent)\n",
    "    return texts_out\n",
    "\n",
    "# Remove Stop Words\n",
    "print('Destroying stop words...')\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "print('Forming bigrams...')\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "print('Building spacy NLP parser...')\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "print('Lemmatizing bigrams...')\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "# Create Dictionary\n",
    "print('Building dictionary...')\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "print('Making corpus...')\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "topic_sizes = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90, 100, 200]\n",
    "lda_models = [] * len(topic_sizes)\n",
    "coherence_model_ldas = [] * len(topic_sizes)\n",
    "coherence_lda = np.zeros(len(topic_sizes))\n",
    "\n",
    "# Build LDA model\n",
    "print('Generating LDA Model...')\n",
    "#for index, topics in enumerate(topic_sizes):\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                   id2word=id2word,\n",
    "                                                   num_topics=1000, \n",
    "                                                   random_state=100,\n",
    "                                                   update_every=1,\n",
    "                                                   chunksize=100,\n",
    "                                                   passes=10,\n",
    "                                                   alpha='auto',\n",
    "                                                   per_word_topics=True)\n",
    "    \n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "doc_lda = lda_model[corpus]\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "# Generate mallet topic\n",
    "mallet_path = '../mallet-2.0.8/bin/mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)\n",
    "\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=32, limit=40, step=6)\n",
    "\n",
    "# Show graph\n",
    "limit=1000; start=1000; step=6;\n",
    "x = range(start, limit, step)\n",
    "\n",
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))\n",
    "\n",
    "# Select the model and print the topics\n",
    "optimal_model = model_list[np.argmax(coherence_values)]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))\n",
    "\n",
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>issue, quickly, accessibility, tool, release, ...</td>\n",
       "      <td>I have always made my course materials publicl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>csc, computer, system, software, planning, cre...</td>\n",
       "      <td>CSC 321 provides an overview of practices, pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>note, session, line, put, request, kind, day, ...</td>\n",
       "      <td>I also think that a successful partnership wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>program, dean, year, fortunate, tuesday, meal,...</td>\n",
       "      <td>As I noted earlier, CSC 207 is the course wher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>question, tutorial, recent, excellent, focus, ...</td>\n",
       "      <td>b.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0          0              0.0689   \n",
       "1          1              0.1490   \n",
       "2          2              0.0979   \n",
       "3          3              0.0793   \n",
       "4          4              0.0578   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  issue, quickly, accessibility, tool, release, ...   \n",
       "1  csc, computer, system, software, planning, cre...   \n",
       "2  note, session, line, put, request, kind, day, ...   \n",
       "3  program, dean, year, fortunate, tuesday, meal,...   \n",
       "4  question, tutorial, recent, excellent, focus, ...   \n",
       "\n",
       "                                                Text  \n",
       "0  I have always made my course materials publicl...  \n",
       "1  CSC 321 provides an overview of practices, pri...  \n",
       "2  I also think that a successful partnership wit...  \n",
       "3  As I noted earlier, CSC 207 is the course wher...  \n",
       "4                                                 b.  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CSC 321 provides an overview of practices, principles, and tools.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_topics_sorteddf_mallet['Text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopicForQuery(question, model=lda_model):\n",
    "    temp = question.lower()\n",
    "\n",
    "    words = re.findall(r'\\w+', temp, flags = re.UNICODE | re.LOCALE)\n",
    "    \n",
    "    important_words = [word for word in simple_preprocess(str(words)) if word not in stop_words]\n",
    "    \n",
    "    dictionary = corpora.Dictionary.load('sam_dict.dict')\n",
    "\n",
    "    ques_vec = dictionary.doc2bow(important_words)\n",
    "\n",
    "    topic_vec = model[[ques_vec]]\n",
    "\n",
    "    likely_topic = max(topic_vec[0], key=itemgetter(1))[0]\n",
    "    \n",
    "    return likely_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In part, \"What did you like best\" is very different than \"What contributed most to your education\".'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dominant_topic = getTopicForQuery('Good morning Samuel Reblesky.', model=optimal_model)\n",
    "related_sentences = df_dominant_topic[df_dominant_topic['Dominant_Topic'] == query_dominant_topic].reset_index(drop=True)\n",
    "related_sentences.loc[random.randint(0,len(related_sentences))]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word.save('sam_dict.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1324)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_topics().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On Friday, I was reading the Scarlet and Black, Grinnell\\'s weekly newspaper [1].  In it was a short interview with the Overcoats [2], a band who are playing Grinnell on November 16.  The first question is \"What kind of music did you both grow up listening to?\"  Hana Elion\\'s response starts \"I liked the classics like [...]\". Now, that\\'s a phrase that many pop and rock musicians say.  In the 60\\'s, the classics typically referred to artists like Elvis, Howlin\\' Wolf, Hank Williams, Junior Parker and such.  By the 70\\'s, the classics were artists like The Beatles, The Stones, The Who, Motown, Otis, James Brown, Dylan, Aretha and perhaps even the Velvets.  Moving forward a decade or two, one would probably add artists like Springsteen, Fleetwood Mac, Prince, and Michael Jackson.  I\\'m not sure that anyone ever referred to the late 1970\\'s punk and new wave acts as \"classics\".  However, by this time, it seems that Patti Smith, the Ramones, Hsker D, the Jam, the Beat, and other such acts are classics. But how did Elion continue their [3] response?  \"I liked the classics like Britney Spears, Backstreet Boys, Dixie Chicks, stuff like that.\" And now I\\'m left wondering Am I just old? Is Elion just really young? Is Elion so sick of that question that they come up with absurdist replies? Is the world ending? I\\'m probably just old.  I think I\\'ll just go listen to some Ella  Fitzgerald.   [1] I was going to say \"Oldest continuously published student newspaper west of the Mississippi\", but it no longer puts that in the title line. I\\'m not sure why it got dropped. [2] No, not the Raincoats.  Didn\\'t they break up like thirty years ago? [3] I do not know what Elion prefers as a pronoun.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[4].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               content\n",
      "0    On Tuesday at lunch, I'm part of a small group...\n",
      "1    I think this is one of those times that I need...\n",
      "2       I hope I don't get myself in too much trouble.\n",
      "3    Shared governance is a core aspect of higher e...\n",
      "4    Its basic premise should be simple: The facult...\n",
      "5    That is, they make decisions collaboratively w...\n",
      "6    At times, collaboration may take the form on c...\n",
      "7    Shared governance usually requires some form o...\n",
      "8    That is, because it is complicated to delibera...\n",
      "9    Those representative groups then have a respon...\n",
      "10    Successful shared governance is open governance.\n",
      "11   Representative groups cannot communicate the w...\n",
      "12   Whenever possible (and it's not always possibl...\n",
      "13   Admittedly, shared governance includes some ac...\n",
      "14   Ideally, in both case that \"ownership\" is stil...\n",
      "15   I am concerned about the current status of sha...\n",
      "16                                                Why?\n",
      "17   First, we have had difficulties with transpare...\n",
      "18   We've had that problem for some time, and it d...\n",
      "19   Second, and perhaps more importantly, decision...\n",
      "20                                Why do I think that?\n",
      "21   It's not because of the Posse decision [1], al...\n",
      "22   It's because of the slew of small and not so s...\n",
      "23                       Let's consider some examples.\n",
      "24   The Faculty Organization Committee (FOC) [2] i...\n",
      "25   In the past few years, I've seen the administr...\n",
      "26   The Instructional Support Committee (ISC) is r...\n",
      "27   But changes to the Web site were made without ...\n",
      "28   ISC's responsibilities are also supposed to in...\n",
      "29   In particular, ISC is supposed to \"raise issue...\n",
      "..                                                 ...\n",
      "519  They are not afraid to engage in difficult con...\n",
      "520              They speak well about their work [4].\n",
      "521                     They are helpful and friendly.\n",
      "522  And, when they are asked to do work, they work...\n",
      "523  I am fortunate to teach at an institution that...\n",
      "524  In general, our students who have papers or po...\n",
      "525  On the other hand, I am also unfortunate in th...\n",
      "526  So I sometimes end up with more work in that c...\n",
      "527                         In balance, it's worth it.\n",
      "528  Postscript: As I've noted in the past, my prim...\n",
      "529                  I am very proud of my three sons.\n",
      "530                 I am married to a wonderful women.\n",
      "531  And my parents were thoughtful, inspirational ...\n",
      "532  But my experience at SIGCSE (other than missin...\n",
      "533  Postscript: I am fortunate in many other aspec...\n",
      "534  These are just the ones that immediately came ...\n",
      "535           [1] That discipline is computer science.\n",
      "536  [2] And I know that they don't always agree wi...\n",
      "537         [3] We've done this acronym before, right?\n",
      "538                        PITA is \"Pain in the Neck\".\n",
      "539  [4] They did well enough that they were one of...\n",
      "540                       [5] Or any other conference.\n",
      "541  [6] The College pays for students' travel, hot...\n",
      "542            Meals are currently cappted at $25/day.\n",
      "543  I'm trying to convince the College to make the...\n",
      "544                     [7] It may be worse than that.\n",
      "545       I seem to be good at saying \"I can do that.\"\n",
      "546  [8] Some people know that I struggle with proc...\n",
      "547                [9] Or perhaps just overcommitment.\n",
      "548                   Version 1.0 released 2018-02-25.\n",
      "\n",
      "[549 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "[[score for topic_id, score in topic] for topic in [doc for doc in lda_corpus]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'0.166*\"good\" + 0.126*\"think\" + 0.070*\"well\" + 0.065*\"note\" + 0.053*\"help\" + 0.039*\"problem\" + 0.020*\"session\" + 0.020*\"postscript\" + 0.020*\"family\" + 0.020*\"fortune\"'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topic(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>make, shared_governance, form, discuss, chair,...</td>\n",
       "      <td>On Tuesday at lunch, I'm part of a small group...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>question, tutorial, recent, excellent, focus, ...</td>\n",
       "      <td>I think this is one of those times that I need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>goa, department, aspect, sit, talk, wait, rebe...</td>\n",
       "      <td>I hope I don't get myself in too much trouble.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>make, shared_governance, form, discuss, chair,...</td>\n",
       "      <td>Shared governance is a core aspect of higher e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>change, policy, isc, hear, administration, sig...</td>\n",
       "      <td>Its basic premise should be simple: The facult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>good, campus, problem, teaching, colleague, ba...</td>\n",
       "      <td>That is, they make decisions collaboratively w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>faculty, topic, small, stuff, interesting, str...</td>\n",
       "      <td>At times, collaboration may take the form on c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>make, shared_governance, form, discuss, chair,...</td>\n",
       "      <td>Shared governance usually requires some form o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>group, people, discipline, grinnell, research,...</td>\n",
       "      <td>That is, because it is complicated to delibera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>group, people, discipline, grinnell, research,...</td>\n",
       "      <td>Those representative groups then have a respon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>long, support, term, governance, suggest, goal...</td>\n",
       "      <td>Successful shared governance is open governance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>faculty, topic, small, stuff, interesting, str...</td>\n",
       "      <td>Representative groups cannot communicate the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>make, page, involve, strong, cgi, create, play...</td>\n",
       "      <td>Whenever possible (and it's not always possibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>long, support, term, governance, suggest, goal...</td>\n",
       "      <td>Admittedly, shared governance includes some ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>faculty, topic, small, stuff, interesting, str...</td>\n",
       "      <td>Ideally, in both case that \"ownership\" is stil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>make, shared_governance, form, discuss, chair,...</td>\n",
       "      <td>I am concerned about the current status of sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>make, page, involve, strong, cgi, create, play...</td>\n",
       "      <td>Why?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>good, campus, problem, teaching, colleague, ba...</td>\n",
       "      <td>First, we have had difficulties with transpare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>good, campus, problem, teaching, colleague, ba...</td>\n",
       "      <td>We've had that problem for some time, and it d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>issue, quickly, accessibility, tool, release, ...</td>\n",
       "      <td>Second, and perhaps more importantly, decision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>decision, committee, senior, design, text, lar...</td>\n",
       "      <td>Why do I think that?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>faculty, topic, small, stuff, interesting, str...</td>\n",
       "      <td>It's not because of the Posse decision [1], al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>issue, quickly, accessibility, tool, release, ...</td>\n",
       "      <td>It's because of the slew of small and not so s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>decision, committee, senior, design, text, lar...</td>\n",
       "      <td>Let's consider some examples.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>change, policy, isc, hear, administration, sig...</td>\n",
       "      <td>The Faculty Organization Committee (FOC) [2] i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>site, web, sketch, study, attend, generate, te...</td>\n",
       "      <td>In the past few years, I've seen the administr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>change, policy, isc, hear, administration, sig...</td>\n",
       "      <td>The Instructional Support Committee (ISC) is r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>change, policy, isc, hear, administration, sig...</td>\n",
       "      <td>But changes to the Web site were made without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>provide, include, start, report, issue, hard, ...</td>\n",
       "      <td>ISC's responsibilities are also supposed to in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>change, policy, isc, hear, administration, sig...</td>\n",
       "      <td>In particular, ISC is supposed to \"raise issue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>519</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>student, professional, reader, grinnell, wonde...</td>\n",
       "      <td>They are not afraid to engage in difficult con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>520</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>group, people, discipline, grinnell, research,...</td>\n",
       "      <td>They speak well about their work [4].</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>521</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>change, policy, isc, hear, administration, sig...</td>\n",
       "      <td>They are helpful and friendly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>522</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>student, professional, reader, grinnell, wonde...</td>\n",
       "      <td>And, when they are asked to do work, they work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>523</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>member, sigcse, list, information, care, remin...</td>\n",
       "      <td>I am fortunate to teach at an institution that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>524</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>group, people, discipline, grinnell, research,...</td>\n",
       "      <td>In general, our students who have papers or po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>525</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>major, choose, interface, computer_science, ye...</td>\n",
       "      <td>On the other hand, I am also unfortunate in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>526</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>learn, add, programming, belong, series, sense...</td>\n",
       "      <td>So I sometimes end up with more work in that c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>527</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>program, dean, year, fortunate, tuesday, meal,...</td>\n",
       "      <td>In balance, it's worth it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>528</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>student, grinnell, content, regard, person, ca...</td>\n",
       "      <td>Postscript: As I've noted in the past, my prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>529</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>teach, structure, serve, face, conference, sci...</td>\n",
       "      <td>I am very proud of my three sons.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>530</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>student, grinnell, content, regard, person, ca...</td>\n",
       "      <td>I am married to a wonderful women.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>531</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>note, session, line, put, request, kind, day, ...</td>\n",
       "      <td>And my parents were thoughtful, inspirational ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>program, dean, year, fortunate, tuesday, meal,...</td>\n",
       "      <td>But my experience at SIGCSE (other than missin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>533</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>find, approach, give, benefit, perspective, co...</td>\n",
       "      <td>Postscript: I am fortunate in many other aspec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>534</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>good, campus, problem, teaching, colleague, ba...</td>\n",
       "      <td>These are just the ones that immediately came ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>535</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>time, write, discussion, curriculum, late, sim...</td>\n",
       "      <td>[1] That discipline is computer science.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>536</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>site, web, sketch, study, attend, generate, te...</td>\n",
       "      <td>[2] And I know that they don't always agree wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>issue, quickly, accessibility, tool, release, ...</td>\n",
       "      <td>[3] We've done this acronym before, right?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PITA is \"Pain in the Neck\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[4] They did well enough that they were one of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[5] Or any other conference.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[6] The College pays for students' travel, hot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meals are currently cappted at $25/day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm trying to convince the College to make the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7] It may be worse than that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I seem to be good at saying \"I can do that.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8] Some people know that I struggle with proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[9] Or perhaps just overcommitment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Version 1.0 released 2018-02-25.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>549 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0              0              23              0.0940   \n",
       "1              1               4              0.0533   \n",
       "2              2              13              0.0424   \n",
       "3              3              23              0.0421   \n",
       "4              4              15              0.0497   \n",
       "5              5              30              0.0421   \n",
       "6              6               9              0.0562   \n",
       "7              7              23              0.0764   \n",
       "8              8              10              0.0857   \n",
       "9              9              10              0.0553   \n",
       "10            10               7              0.0429   \n",
       "11            11               9              0.0731   \n",
       "12            12              12              0.0513   \n",
       "13            13               7              0.0664   \n",
       "14            14               9              0.0532   \n",
       "15            15              23              0.0441   \n",
       "16            16              12              0.0553   \n",
       "17            17              30              0.0542   \n",
       "18            18              30              0.0543   \n",
       "19            19               0              0.0263   \n",
       "20            20              35              0.0583   \n",
       "21            21               9              0.0660   \n",
       "22            22               0              0.0263   \n",
       "23            23              35              0.0591   \n",
       "24            24              15              0.0516   \n",
       "25            25              25              0.0709   \n",
       "26            26              15              0.1334   \n",
       "27            27              15              0.0406   \n",
       "28            28              16              0.0872   \n",
       "29            29              15              0.0694   \n",
       "..           ...             ...                 ...   \n",
       "519          519              32              0.0416   \n",
       "520          520              10              0.0473   \n",
       "521          521              15              0.0701   \n",
       "522          522              32              0.0562   \n",
       "523          523              20              0.0458   \n",
       "524          524              10              0.0445   \n",
       "525          525              17              0.0432   \n",
       "526          526              18              0.0432   \n",
       "527          527               3              0.0416   \n",
       "528          528               6              0.0873   \n",
       "529          529              36              0.0432   \n",
       "530          530               6              0.0533   \n",
       "531          531               2              0.0416   \n",
       "532          532               3              0.0482   \n",
       "533          533              27              0.0432   \n",
       "534          534              30              0.0367   \n",
       "535          535              37              0.0426   \n",
       "536          536              25              0.0389   \n",
       "537          537               0              0.0445   \n",
       "538          538             NaN                 NaN   \n",
       "539          539             NaN                 NaN   \n",
       "540          540             NaN                 NaN   \n",
       "541          541             NaN                 NaN   \n",
       "542          542             NaN                 NaN   \n",
       "543          543             NaN                 NaN   \n",
       "544          544             NaN                 NaN   \n",
       "545          545             NaN                 NaN   \n",
       "546          546             NaN                 NaN   \n",
       "547          547             NaN                 NaN   \n",
       "548          548             NaN                 NaN   \n",
       "\n",
       "                                              Keywords  \\\n",
       "0    make, shared_governance, form, discuss, chair,...   \n",
       "1    question, tutorial, recent, excellent, focus, ...   \n",
       "2    goa, department, aspect, sit, talk, wait, rebe...   \n",
       "3    make, shared_governance, form, discuss, chair,...   \n",
       "4    change, policy, isc, hear, administration, sig...   \n",
       "5    good, campus, problem, teaching, colleague, ba...   \n",
       "6    faculty, topic, small, stuff, interesting, str...   \n",
       "7    make, shared_governance, form, discuss, chair,...   \n",
       "8    group, people, discipline, grinnell, research,...   \n",
       "9    group, people, discipline, grinnell, research,...   \n",
       "10   long, support, term, governance, suggest, goal...   \n",
       "11   faculty, topic, small, stuff, interesting, str...   \n",
       "12   make, page, involve, strong, cgi, create, play...   \n",
       "13   long, support, term, governance, suggest, goal...   \n",
       "14   faculty, topic, small, stuff, interesting, str...   \n",
       "15   make, shared_governance, form, discuss, chair,...   \n",
       "16   make, page, involve, strong, cgi, create, play...   \n",
       "17   good, campus, problem, teaching, colleague, ba...   \n",
       "18   good, campus, problem, teaching, colleague, ba...   \n",
       "19   issue, quickly, accessibility, tool, release, ...   \n",
       "20   decision, committee, senior, design, text, lar...   \n",
       "21   faculty, topic, small, stuff, interesting, str...   \n",
       "22   issue, quickly, accessibility, tool, release, ...   \n",
       "23   decision, committee, senior, design, text, lar...   \n",
       "24   change, policy, isc, hear, administration, sig...   \n",
       "25   site, web, sketch, study, attend, generate, te...   \n",
       "26   change, policy, isc, hear, administration, sig...   \n",
       "27   change, policy, isc, hear, administration, sig...   \n",
       "28   provide, include, start, report, issue, hard, ...   \n",
       "29   change, policy, isc, hear, administration, sig...   \n",
       "..                                                 ...   \n",
       "519  student, professional, reader, grinnell, wonde...   \n",
       "520  group, people, discipline, grinnell, research,...   \n",
       "521  change, policy, isc, hear, administration, sig...   \n",
       "522  student, professional, reader, grinnell, wonde...   \n",
       "523  member, sigcse, list, information, care, remin...   \n",
       "524  group, people, discipline, grinnell, research,...   \n",
       "525  major, choose, interface, computer_science, ye...   \n",
       "526  learn, add, programming, belong, series, sense...   \n",
       "527  program, dean, year, fortunate, tuesday, meal,...   \n",
       "528  student, grinnell, content, regard, person, ca...   \n",
       "529  teach, structure, serve, face, conference, sci...   \n",
       "530  student, grinnell, content, regard, person, ca...   \n",
       "531  note, session, line, put, request, kind, day, ...   \n",
       "532  program, dean, year, fortunate, tuesday, meal,...   \n",
       "533  find, approach, give, benefit, perspective, co...   \n",
       "534  good, campus, problem, teaching, colleague, ba...   \n",
       "535  time, write, discussion, curriculum, late, sim...   \n",
       "536  site, web, sketch, study, attend, generate, te...   \n",
       "537  issue, quickly, accessibility, tool, release, ...   \n",
       "538                                                NaN   \n",
       "539                                                NaN   \n",
       "540                                                NaN   \n",
       "541                                                NaN   \n",
       "542                                                NaN   \n",
       "543                                                NaN   \n",
       "544                                                NaN   \n",
       "545                                                NaN   \n",
       "546                                                NaN   \n",
       "547                                                NaN   \n",
       "548                                                NaN   \n",
       "\n",
       "                                                  Text  \n",
       "0    On Tuesday at lunch, I'm part of a small group...  \n",
       "1    I think this is one of those times that I need...  \n",
       "2       I hope I don't get myself in too much trouble.  \n",
       "3    Shared governance is a core aspect of higher e...  \n",
       "4    Its basic premise should be simple: The facult...  \n",
       "5    That is, they make decisions collaboratively w...  \n",
       "6    At times, collaboration may take the form on c...  \n",
       "7    Shared governance usually requires some form o...  \n",
       "8    That is, because it is complicated to delibera...  \n",
       "9    Those representative groups then have a respon...  \n",
       "10    Successful shared governance is open governance.  \n",
       "11   Representative groups cannot communicate the w...  \n",
       "12   Whenever possible (and it's not always possibl...  \n",
       "13   Admittedly, shared governance includes some ac...  \n",
       "14   Ideally, in both case that \"ownership\" is stil...  \n",
       "15   I am concerned about the current status of sha...  \n",
       "16                                                Why?  \n",
       "17   First, we have had difficulties with transpare...  \n",
       "18   We've had that problem for some time, and it d...  \n",
       "19   Second, and perhaps more importantly, decision...  \n",
       "20                                Why do I think that?  \n",
       "21   It's not because of the Posse decision [1], al...  \n",
       "22   It's because of the slew of small and not so s...  \n",
       "23                       Let's consider some examples.  \n",
       "24   The Faculty Organization Committee (FOC) [2] i...  \n",
       "25   In the past few years, I've seen the administr...  \n",
       "26   The Instructional Support Committee (ISC) is r...  \n",
       "27   But changes to the Web site were made without ...  \n",
       "28   ISC's responsibilities are also supposed to in...  \n",
       "29   In particular, ISC is supposed to \"raise issue...  \n",
       "..                                                 ...  \n",
       "519  They are not afraid to engage in difficult con...  \n",
       "520              They speak well about their work [4].  \n",
       "521                     They are helpful and friendly.  \n",
       "522  And, when they are asked to do work, they work...  \n",
       "523  I am fortunate to teach at an institution that...  \n",
       "524  In general, our students who have papers or po...  \n",
       "525  On the other hand, I am also unfortunate in th...  \n",
       "526  So I sometimes end up with more work in that c...  \n",
       "527                         In balance, it's worth it.  \n",
       "528  Postscript: As I've noted in the past, my prim...  \n",
       "529                  I am very proud of my three sons.  \n",
       "530                 I am married to a wonderful women.  \n",
       "531  And my parents were thoughtful, inspirational ...  \n",
       "532  But my experience at SIGCSE (other than missin...  \n",
       "533  Postscript: I am fortunate in many other aspec...  \n",
       "534  These are just the ones that immediately came ...  \n",
       "535           [1] That discipline is computer science.  \n",
       "536  [2] And I know that they don't always agree wi...  \n",
       "537         [3] We've done this acronym before, right?  \n",
       "538                        PITA is \"Pain in the Neck\".  \n",
       "539  [4] They did well enough that they were one of...  \n",
       "540                       [5] Or any other conference.  \n",
       "541  [6] The College pays for students' travel, hot...  \n",
       "542            Meals are currently cappted at $25/day.  \n",
       "543  I'm trying to convince the College to make the...  \n",
       "544                     [7] It may be worse than that.  \n",
       "545       I seem to be good at saying \"I can do that.\"  \n",
       "546  [8] Some people know that I struggle with proc...  \n",
       "547                [9] Or perhaps just overcommitment.  \n",
       "548                   Version 1.0 released 2018-02-25.  \n",
       "\n",
       "[549 rows x 5 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
